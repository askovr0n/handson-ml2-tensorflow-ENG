{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this exercise, I will perform DNN based on dataset CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Create a deep network consisting of 20 hidden layers containing 100 neurons each (there are too many, but that's the moral of the exercise). Use the He initialisation and the ELU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "network = keras.models.Sequential()\n",
    "network.add(keras.layers.Flatten(input_shape = [32,32,3]))\n",
    "\n",
    "for _ in range(20):\n",
    "    network.add(keras.layers.Dense(100, \n",
    "                                  kernel_initializer=\"he_normal\", # these parameters are default values\n",
    "                                  activation=\"elu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Exercise: Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with keras.datasets.cifar10.load_data(). The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you'll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model's architecture or hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test_full, y_test_full) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape, X_test_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As validation dataset, I will use 5000 observations of each training and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will build my optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1407/1407 [==============================] - 28s 16ms/step - loss: 2.9553 - accuracy: 0.2145 - val_loss: 2.1783 - val_accuracy: 0.2208\n",
      "Epoch 2/50\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.9279 - accuracy: 0.2888 - val_loss: 1.9115 - val_accuracy: 0.2828\n",
      "Epoch 3/50\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.8716 - accuracy: 0.3127 - val_loss: 1.9317 - val_accuracy: 0.2900\n",
      "Epoch 4/50\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.8283 - accuracy: 0.3306 - val_loss: 1.9108 - val_accuracy: 0.2864\n",
      "Epoch 5/50\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.8128 - accuracy: 0.3384 - val_loss: 1.9881 - val_accuracy: 0.3264\n",
      "Epoch 6/50\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 1.7759 - accuracy: 0.3563 - val_loss: 1.8421 - val_accuracy: 0.3458\n",
      "Epoch 7/50\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.7508 - accuracy: 0.3672 - val_loss: 1.8397 - val_accuracy: 0.3354\n",
      "Epoch 8/50\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.7290 - accuracy: 0.3752 - val_loss: 1.7390 - val_accuracy: 0.3764\n",
      "Epoch 9/50\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.7437 - accuracy: 0.3725 - val_loss: 1.8086 - val_accuracy: 0.3402\n",
      "Epoch 10/50\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.6995 - accuracy: 0.3886 - val_loss: 1.7091 - val_accuracy: 0.3842\n",
      "Epoch 11/50\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.6848 - accuracy: 0.3935 - val_loss: 1.6972 - val_accuracy: 0.3834\n",
      "Epoch 12/50\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.6663 - accuracy: 0.4016 - val_loss: 1.8367 - val_accuracy: 0.3478\n",
      "Epoch 13/50\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.9067 - accuracy: 0.3785 - val_loss: 2.3208 - val_accuracy: 0.1376\n",
      "Epoch 14/50\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 2.1212 - accuracy: 0.2006 - val_loss: 2.0045 - val_accuracy: 0.2432\n",
      "Epoch 15/50\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.9669 - accuracy: 0.2545 - val_loss: 1.9327 - val_accuracy: 0.2570\n",
      "Epoch 16/50\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.9191 - accuracy: 0.2741 - val_loss: 1.9084 - val_accuracy: 0.2756\n",
      "Epoch 17/50\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.8987 - accuracy: 0.2801 - val_loss: 1.8961 - val_accuracy: 0.2862\n",
      "Epoch 18/50\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.8855 - accuracy: 0.2888 - val_loss: 1.8967 - val_accuracy: 0.2940\n",
      "Epoch 19/50\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.8723 - accuracy: 0.2944 - val_loss: 1.8753 - val_accuracy: 0.2902\n",
      "Epoch 20/50\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.8579 - accuracy: 0.3030 - val_loss: 1.9429 - val_accuracy: 0.3028\n",
      "Epoch 21/50\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.8266 - accuracy: 0.3223 - val_loss: 1.8431 - val_accuracy: 0.3258\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6972 - accuracy: 0.3834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6971863508224487, 0.38339999318122864]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.001)\n",
    "network.compile(loss = 'sparse_categorical_crossentropy',\n",
    "                optimizer = optimizer,\n",
    "                metrics = [\"accuracy\"])\n",
    "\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10) # Because of early stopping, I have created validation dataset\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"GNN_exercise_2.h5\", save_best_only=True)\n",
    "callbacks = [early_stopping_cb, checkpoint_cb]\n",
    "\n",
    "network.fit(X_train, y_train, epochs = 50,\n",
    "            validation_data = [X_valid, y_valid],\n",
    "            callbacks = callbacks)\n",
    "\n",
    "network = keras.models.load_model(\"GNN_exercise_2.h5\")\n",
    "network.evaluate(X_valid, y_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it affect training speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1407/1407 [==============================] - 46s 23ms/step - loss: 1.8465 - accuracy: 0.3364 - val_loss: 1.6822 - val_accuracy: 0.3910\n",
      "Epoch 2/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.6903 - accuracy: 0.4000 - val_loss: 1.6440 - val_accuracy: 0.4064\n",
      "Epoch 3/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.6234 - accuracy: 0.4221 - val_loss: 1.5868 - val_accuracy: 0.4316\n",
      "Epoch 4/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.5627 - accuracy: 0.4450 - val_loss: 1.4923 - val_accuracy: 0.4600\n",
      "Epoch 5/50\n",
      "1407/1407 [==============================] - 32s 22ms/step - loss: 1.5203 - accuracy: 0.4589 - val_loss: 1.5501 - val_accuracy: 0.4456\n",
      "Epoch 6/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.4868 - accuracy: 0.4744 - val_loss: 1.4727 - val_accuracy: 0.4698\n",
      "Epoch 7/50\n",
      "1407/1407 [==============================] - 32s 22ms/step - loss: 1.4473 - accuracy: 0.4866 - val_loss: 1.4517 - val_accuracy: 0.4876\n",
      "Epoch 8/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.4198 - accuracy: 0.4966 - val_loss: 1.4066 - val_accuracy: 0.4982\n",
      "Epoch 9/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.3905 - accuracy: 0.5073 - val_loss: 1.4328 - val_accuracy: 0.5002\n",
      "Epoch 10/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.3670 - accuracy: 0.5132 - val_loss: 1.3991 - val_accuracy: 0.5068\n",
      "Epoch 11/50\n",
      "1407/1407 [==============================] - 32s 22ms/step - loss: 1.3464 - accuracy: 0.5188 - val_loss: 1.4475 - val_accuracy: 0.4842\n",
      "Epoch 12/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.3305 - accuracy: 0.5278 - val_loss: 1.3781 - val_accuracy: 0.5188\n",
      "Epoch 13/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.3072 - accuracy: 0.5372 - val_loss: 1.3869 - val_accuracy: 0.5112\n",
      "Epoch 14/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.2877 - accuracy: 0.5440 - val_loss: 1.3218 - val_accuracy: 0.5256\n",
      "Epoch 15/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.2675 - accuracy: 0.5534 - val_loss: 1.3418 - val_accuracy: 0.5316\n",
      "Epoch 16/50\n",
      "1407/1407 [==============================] - 32s 22ms/step - loss: 1.2475 - accuracy: 0.5577 - val_loss: 1.3448 - val_accuracy: 0.5278\n",
      "Epoch 17/50\n",
      "1407/1407 [==============================] - 32s 22ms/step - loss: 1.2325 - accuracy: 0.5637 - val_loss: 1.3519 - val_accuracy: 0.5324\n",
      "Epoch 18/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.2151 - accuracy: 0.5717 - val_loss: 1.3696 - val_accuracy: 0.5212\n",
      "Epoch 19/50\n",
      "1407/1407 [==============================] - 31s 22ms/step - loss: 1.2006 - accuracy: 0.5791 - val_loss: 1.3348 - val_accuracy: 0.5340\n",
      "Epoch 20/50\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 1.1925 - accuracy: 0.5797 - val_loss: 1.3442 - val_accuracy: 0.5426\n",
      "Epoch 21/50\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 1.1731 - accuracy: 0.5843 - val_loss: 1.3399 - val_accuracy: 0.5348\n",
      "Epoch 22/50\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 1.1566 - accuracy: 0.5914 - val_loss: 1.3499 - val_accuracy: 0.5298\n",
      "Epoch 23/50\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 1.1453 - accuracy: 0.5959 - val_loss: 1.3637 - val_accuracy: 0.5330\n",
      "Epoch 24/50\n",
      "1407/1407 [==============================] - 30s 21ms/step - loss: 1.1298 - accuracy: 0.6028 - val_loss: 1.2998 - val_accuracy: 0.5452\n",
      "Epoch 25/50\n",
      "1407/1407 [==============================] - 32s 22ms/step - loss: 1.1134 - accuracy: 0.6071 - val_loss: 1.3803 - val_accuracy: 0.5128\n",
      "Epoch 26/50\n",
      "1407/1407 [==============================] - 32s 22ms/step - loss: 1.1026 - accuracy: 0.6110 - val_loss: 1.3707 - val_accuracy: 0.5316\n",
      "Epoch 27/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.0913 - accuracy: 0.6132 - val_loss: 1.3313 - val_accuracy: 0.5328\n",
      "Epoch 28/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.0803 - accuracy: 0.6193 - val_loss: 1.3323 - val_accuracy: 0.5390\n",
      "Epoch 29/50\n",
      "1407/1407 [==============================] - 32s 22ms/step - loss: 1.0679 - accuracy: 0.6240 - val_loss: 1.3519 - val_accuracy: 0.5380\n",
      "Epoch 30/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.0546 - accuracy: 0.6301 - val_loss: 1.3701 - val_accuracy: 0.5380\n",
      "Epoch 31/50\n",
      "1407/1407 [==============================] - 32s 22ms/step - loss: 1.0551 - accuracy: 0.6278 - val_loss: 1.3209 - val_accuracy: 0.5450\n",
      "Epoch 32/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.0303 - accuracy: 0.6401 - val_loss: 1.3525 - val_accuracy: 0.5398\n",
      "Epoch 33/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.0264 - accuracy: 0.6382 - val_loss: 1.3518 - val_accuracy: 0.5484\n",
      "Epoch 34/50\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.0210 - accuracy: 0.6436 - val_loss: 1.3464 - val_accuracy: 0.5384\n",
      "157/157 [==============================] - 2s 6ms/step - loss: 1.2998 - accuracy: 0.5452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.299830675125122, 0.545199990272522]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "network_batched = keras.models.Sequential()\n",
    "network_batched.add(keras.layers.Flatten(input_shape = [32,32,3]))\n",
    "network_batched.add(keras.layers.BatchNormalization())\n",
    "\n",
    "for _ in range(20):\n",
    "    network_batched.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    network_batched.add(keras.layers.BatchNormalization())\n",
    "    network_batched.add(keras.layers.Activation(\"elu\"))\n",
    "network_batched.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.001)\n",
    "network_batched.compile(loss = 'sparse_categorical_crossentropy',\n",
    "                optimizer = optimizer,\n",
    "                metrics = [\"accuracy\"])\n",
    "\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10) # Because of early stopping, I have created validation dataset\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"GNN_exercise_2_1.h5\", save_best_only=True)\n",
    "callbacks = [early_stopping_cb, checkpoint_cb]\n",
    "\n",
    "network_batched.fit(X_train, y_train, epochs = 50,\n",
    "            validation_data = [X_valid, y_valid],\n",
    "            callbacks = callbacks)\n",
    "\n",
    "network_batched = keras.models.load_model(\"GNN_exercise_2_1.h5\")\n",
    "network_batched.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58c6268f8c0b696f0c5de63073949a37c81bc2ff28536b69e37f15be4ce332ad"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
